{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intel Image Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will show how to do image classification with six different classes. The model will be constructed useing transfered learning implemented with the keras imagenet as the base model. The image data is from kaggle and can be found [here](https://www.kaggle.com/puneet6060/intel-image-classification)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up egpu using plaidml\n",
    "import os\n",
    "\n",
    "os.environ[\"KERAS_BACKEND\"] = \"plaidml.keras.backend\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import keras layers , activation funtions and optimizers\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras.layers.advanced_activations import LeakyReLU, PReLU\n",
    "from keras import optimizers\n",
    "\n",
    "# dimensions of our images.\n",
    "img_width, img_height = 300, 300\n",
    "\n",
    "# set directory\n",
    "train_data_dir = 'intel-image-classification/train'\n",
    "validation_data_dir = 'intel-image-classification/test'\n",
    "\n",
    "# steps per epoch\n",
    "nb_train_samples = 2000\n",
    "nb_validation_samples = 800\n",
    "epochs = 5\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imprt keras applications\n",
    "from keras.layers import GlobalAveragePooling2D\n",
    "from keras.applications import MobileNet\n",
    "from keras.applications.mobilenet import preprocess_input\n",
    "\n",
    "# dowload imagenet weights without the final layer\n",
    "base_model=MobileNet(weights='imagenet',include_top=False) \n",
    "\n",
    "# add dense layers so that that the model performs better on our data\n",
    "x=base_model.output\n",
    "x=GlobalAveragePooling2D()(x)\n",
    "x=Dense(1024,activation='relu')(x) \n",
    "x=Dense(1024,activation='relu')(x) \n",
    "x=Dense(512,activation='relu')(x) \n",
    "x=Dense(128,activation='relu')(x)\n",
    "preds=Dense(6,activation='softmax')(x) #final layer with softmax activation and six outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import keras Model to connect the base model and our custom model outputs\n",
    "from keras.models import Model\n",
    "\n",
    "# specify model inputs and outputs\n",
    "model=Model(inputs=base_model.input,outputs=preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# freeze the base model parameters\n",
    "for layer in model.layers[:20]:\n",
    "    layer.trainable=False\n",
    "# make final 20 model layer traianble \n",
    "for layer in model.layers[20:]:\n",
    "    layer.trainable=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the augmentation configuration we will use for training\n",
    "train_datagen = ImageDataGenerator(\n",
    "rescale=1. / 255,\n",
    "shear_range=0.2,\n",
    "zoom_range=0.2,\n",
    "horizontal_flip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 14034 images belonging to 6 classes.\n",
      "Found 3000 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "# this is the augmentation configuration we will use for testing\n",
    "# only rescaling\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "target_size=(img_width, img_height),\n",
    "batch_size=batch_size,\n",
    "class_mode='binary')\n",
    "\n",
    "# this is the augmentation configuration we will use for testing\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "target_size=(img_width, img_height),\n",
    "batch_size=batch_size,\n",
    "class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define optimizer\n",
    "opt = optimizers.Nadam(lr=.0001)\n",
    "# compile model\n",
    "model.compile(optimizer=opt,loss='sparse_categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "125/125 [==============================] - 69s 551ms/step - loss: 0.2619 - acc: 0.9065 - val_loss: 0.3436 - val_acc: 0.8875\n",
      "Epoch 2/5\n",
      "125/125 [==============================] - 68s 548ms/step - loss: 0.2278 - acc: 0.9260 - val_loss: 0.3589 - val_acc: 0.8838\n",
      "Epoch 3/5\n",
      "125/125 [==============================] - 69s 553ms/step - loss: 0.2428 - acc: 0.9200 - val_loss: 0.3173 - val_acc: 0.9025\n",
      "Epoch 4/5\n",
      "125/125 [==============================] - 69s 553ms/step - loss: 0.2319 - acc: 0.9150 - val_loss: 0.3481 - val_acc: 0.8889\n",
      "Epoch 5/5\n",
      "125/125 [==============================] - 70s 557ms/step - loss: 0.2300 - acc: 0.9195 - val_loss: 0.3037 - val_acc: 0.8988\n"
     ]
    }
   ],
   "source": [
    "# fit model to train and validation datasets\n",
    "model.fit_generator(\n",
    "    train_generator,\n",
    "steps_per_epoch=nb_train_samples // batch_size,\n",
    "epochs=epochs,\n",
    "validation_data=validation_generator,\n",
    "validation_steps=nb_validation_samples // batch_size)\n",
    "model.save_weights('fifth_try.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
